"""from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableConfig
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory"""

from langchain_google_vertexai import VertexAIEmbeddings
from langchain_google_vertexai import ChatVertexAI
from langchain_chroma import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph, MessagesState
from langgraph.graph.message import add_messages

import os
import sys
import time
import uuid
from ratelimit import limits, sleep_and_retry
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional, TypedDict


# Configure stdout to handle special characters properly
sys.stdout.reconfigure(encoding='utf-8')

# Load environment variables
dotenv_path = os.path.join(os.path.dirname(__file__), 'db', '.env')
load_dotenv(dotenv_path)

# Credenciales para usar VERTEX_AI
credentials_path = r"C:/Users/Dante/Desktop/rag_docente/db/gen-lang-client-0115469242-239dc466873d.json"
if not os.path.exists(credentials_path):
    raise FileNotFoundError(
        f"No se encontr√≥ el archivo de credenciales en: {credentials_path}")
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
os.environ["LANGSMITH_TRACING"] = "true"

# Para tracear con langsmith
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
if not LANGSMITH_API_KEY:
    raise ValueError(
        "La variable LANGSMITH_API_KEY no est√° definida en el archivo .env en la carpeta db/")
os.environ["LANGSMITH_API_KEY"] = LANGSMITH_API_KEY

# Definir el l√≠mite de peticiones (por ejemplo, 180 por minuto para estar seguros)
CALLS_PER_MINUTE = 150
PERIOD = 60
WAIT_TIME = 1


@sleep_and_retry
@limits(calls=CALLS_PER_MINUTE, period=PERIOD)
def rate_limited_llm_call(func, *args, **kwargs):
    """
    Wrapper function para las llamadas al LLM con rate limiting mejorado
    """
    time.sleep(WAIT_TIME)
    return func(*args, **kwargs)

# Iniciamos con el programa


def load_pdf_documents(directory_path: str) -> List:
    """
    Loads all PDF documents from a given directory and its subdirectories recursively.

    Args:
        directory_path: Path to the directory containing PDF files

    Returns:
        List of Document objects containing the content of the PDFs
    """
    if not os.path.exists(directory_path):
        print(f"Directory {directory_path} does not exist.")
        return []

    documents = []

    # Recorrer el directorio y sus subdirectorios
    for root, dirs, files in os.walk(directory_path):
        pdf_files = [f for f in files if f.endswith('.pdf')]

        for pdf_file in pdf_files:
            try:
                file_path = os.path.join(root, pdf_file)
                print(f"Loading PDF: {file_path}")
                # PyPDFLoader handles both text and images
                loader = PyPDFLoader(file_path)
                documents.extend(loader.load())
                print(
                    f"Successfully loaded {pdf_file} with {len(loader.load())} pages")
            except Exception as e:
                print(f"Error loading {pdf_file}: {e}")

    if not documents:
        print(f"No PDF files found in {directory_path} or its subdirectories.")

    return documents


def create_vectorstore(documents, embeddings, collection_name="pdf-rag-chroma"):
    """
    Crea o carga un Chroma vector store.
    Si la base de datos existe, simplemente la carga sin procesar nuevos documentos.
    Solo crea una nueva si no existe.
    """
    persist_directory = f"./{collection_name}"

    # Si existe la base de datos, cargarla y retornar
    if os.path.exists(persist_directory):
        print(
            f"\nüìö Base de datos Chroma existente encontrada en {persist_directory}")
        try:
            vectorstore = Chroma(
                persist_directory=persist_directory,
                embedding_function=embeddings,
                collection_name=collection_name
            )
            collection_size = len(vectorstore.get()['ids'])
            print(
                f"‚úÖ Vectorstore cargado exitosamente con {collection_size} documentos")
            return vectorstore
        except Exception as e:
            print(f"‚ùå Error cr√≠tico al cargar la base de datos existente: {e}")
            raise e

    # Solo si NO existe la base de datos, crear una nueva
    print("\n‚ö†Ô∏è No se encontr√≥ una base de datos existente. Creando nueva...")

    if not documents:
        raise ValueError(
            "‚ùå No se proporcionaron documentos para crear el vectorstore")

    print("üìÑ Procesando documentos...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=300,
        separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
        length_function=len
    )
    chunks = text_splitter.split_documents(documents)
    print(f"‚úÖ Documentos divididos en {len(chunks)} chunks")

    print("üîÑ Creando nuevo vectorstore...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection_name=collection_name,
        persist_directory=persist_directory
    )

    collection_size = len(vectorstore.get()['ids'])
    print(f"‚úÖ Nuevo vectorstore creado con {collection_size} documentos")

    return vectorstore


def direct_answer_generator(llm, query, documents, source_documents=None, conversation_history=None):
    """
    Genera una respuesta directa basada en los documentos recuperados y el historial de conversaci√≥n.
    Verifica que la solicitud incluya asignatura y nivel antes de generar contenido.
    """
    # Interpretar el tipo de contenido y extraer detalles
    interpret_prompt = [
        SystemMessage(content="""Analiza la consulta del usuario e identifica:
        1. Tipo de contenido solicitado (PLANIFICACI√ìN, EVALUACI√ìN o GU√çA)
        2. Asignatura mencionada
        3. Nivel educativo mencionado

        NIVELES V√ÅLIDOS:
        - Sala Cuna (0-2 a√±os)
        - Nivel Medio (2-4 a√±os)
        - Transici√≥n (4-6 a√±os)
        - 1¬∞ a 6¬∞ B√°sico
        - 7¬∞ b√°sico a 2¬∞ medio
        - 3¬∞ a 4¬∞ medio

        Responde en formato JSON:
        {
            "tipo_contenido": "PLANIFICACI√ìN/EVALUACI√ìN/GU√çA",
            "asignatura": "nombre_asignatura o null si no se menciona",
            "nivel": "nivel_educativo o null si no se menciona",
            "informacion_faltante": ["asignatura" y/o "nivel" si falta alguno]
        }"""),
        HumanMessage(content=query)
    ]

    interpretation = rate_limited_llm_call(llm.invoke, interpret_prompt)

    try:
        # Verificar si falta informaci√≥n esencial
        info = eval(interpretation.content)
        if info.get("informacion_faltante"):
            faltantes = info["informacion_faltante"]
            preguntas = {
                "asignatura": "¬øPara qu√© asignatura necesitas este contenido?",
                "nivel": "¬øPara qu√© nivel educativo necesitas este contenido? (Por ejemplo: 2¬∞ b√°sico, 8¬∞ b√°sico, etc.)"
            }

            mensaje_solicitud = "Para generar el contenido, necesito algunos detalles adicionales:\n\n"
            for faltante in faltantes:
                mensaje_solicitud += f"- {preguntas[faltante]}\n"

            return mensaje_solicitud
    except Exception as e:
        print(f"Error al procesar la interpretaci√≥n: {e}")

    # Si tenemos toda la informaci√≥n necesaria, continuamos con la generaci√≥n del contenido
    if not documents:
        return "No he podido encontrar informaci√≥n relevante para responder a tu pregunta."

    # Format context from documents
    context = "\n\n".join([doc.page_content for doc in documents])

    # Get source information for citation
    sources = []
    if source_documents:
        for doc in source_documents:
            if hasattr(doc, 'metadata') and 'source' in doc.metadata:
                source = doc.metadata['source'].split('\\')[-1]
                if source not in sources:
                    sources.append(source)

    source_text = ", ".join(
        sources) if sources else "los documentos disponibles"

    # Format conversation history if available
    history_text = ""
    if conversation_history and len(conversation_history) > 0:
        history_messages = []
        for msg in conversation_history[-4:]:
            if isinstance(msg, HumanMessage):
                history_messages.append(f"Usuario: {msg.content}")
            elif isinstance(msg, AIMessage):
                history_messages.append(f"Asistente: {msg.content}")
        history_text = "\n".join(history_messages)

    # Create prompt for answer generation based on content type
    system_prompt = f"""Eres un asistente especializado para docentes chilenos que GENERA contenido educativo bas√°ndose
    en los documentos curriculares oficiales almacenados en nuestra base de datos.

    Tu tarea es CREAR uno de estos tres tipos de contenido, seg√∫n lo que solicite el docente:

    Si es PLANIFICACI√ìN:
    1. Objetivo general (extra√≠do de las bases curriculares)
    2. Objetivos espec√≠ficos (m√≠nimo 5, basados en el curr√≠culum nacional)
    3. Contenidos y habilidades asociadas (m√≠nimo 5, seg√∫n nivel y asignatura)
    4. Actividades sugeridas (m√≠nimo 3, adaptadas al contexto chileno)

    Si es EVALUACI√ìN:
    1. 8 preguntas de selecci√≥n m√∫ltiple con 4 opciones cada una
       - Basadas en los objetivos de aprendizaje del curr√≠culum
       - Opciones coherentes con el nivel educativo
    2. 2 preguntas de desarrollo que eval√∫en habilidades superiores
    3. Respuestas gu√≠a fundamentadas en el curr√≠culum nacional

    Si es GU√çA DE ESTUDIO:
    1. Resumen del tema alineado con el curr√≠culum
    2. Conceptos clave seg√∫n las bases curriculares
    3. Ejemplos resueltos contextualizados a la realidad chilena
    4. Ejercicios de pr√°ctica graduados por dificultad

    IMPORTANTE:
    - NO esperes que el usuario te proporcione el contenido
    - GENERA el contenido bas√°ndote en los documentos curriculares de nuestra base de datos
    - ADAPTA el contenido al nivel y asignatura solicitados
    - CITA las fuentes curriculares espec√≠ficas que utilizaste
    - Si no encuentras informaci√≥n suficiente en la base de datos, GENERA una alternativa razonable
      basada en el curr√≠culum nacional, indicando claramente que es una sugerencia
"""

    messages = [
        SystemMessage(content=system_prompt)
    ]

    if history_text:
        messages.append(SystemMessage(content=f"""
        Historial reciente de la conversaci√≥n:
        {history_text}
        """))

    messages.append(HumanMessage(content=f"""
    SOLICITUD DEL USUARIO: {query}
    INTERPRETACI√ìN: {interpretation.content}

    INSTRUCCI√ìN: Bas√°ndote en los documentos curriculares disponibles en el contexto,
    CREA el contenido solicitado. NO eval√∫es contenido existente, GENERA uno nuevo.

    Contexto disponible:
    {context}
    """))

    try:
        answer_result = rate_limited_llm_call(llm.invoke, messages)
        answer_text = answer_result.content.strip()

        # Format final output
        final_response = f"""Basado en {source_text}, aqu√≠ est√° el contenido solicitado:

{answer_text}"""
        return final_response

    except Exception as e:
        print(f"Error generating answer: {e}")
        return f"Lo siento, hubo un error al procesar la respuesta. ¬øPodr√≠as reformular tu pregunta? Error: {str(e)}"


def create_enhanced_retriever_tool(vectorstore, llm, conversation_history=None,
                               tool_name="enhanced_pdf_retriever",
                               tool_description="Busca informaci√≥n espec√≠fica en documentos curriculares chilenos para ayudar a crear planificaciones educativas."):
    """
    Crea una herramienta mejorada que considera el historial de la conversaci√≥n.
    """
    def enhanced_retriever_with_answer(query: str) -> str:
        print(f"Ejecutando b√∫squeda mejorada para: {query}")

        # Si hay historial, usarlo para mejorar la b√∫squeda
        if conversation_history and len(conversation_history) > 0:
            # Crear un prompt para reformular la consulta
            context_prompt = SystemMessage(content="""
            Eres un especialista en educaci√≥n chilena. Tu tarea es reformular la consulta del usuario para extraer informaci√≥n relevante de documentos curriculares que le ayude a crear:

            1. Planificaciones educativas para niveles desde sala cuna hasta educaci√≥n media
            2. Actividades adaptadas al curr√≠culum nacional
            3. Evaluaciones alineadas con objetivos de aprendizaje oficiales

            Basado en el historial de la conversaci√≥n y la pregunta actual, reformula la consulta para encontrar informaci√≥n curricular espec√≠fica que satisfaga la necesidad del docente.
            """)

            try:
                # Reformular la consulta
                enhanced_query_response = rate_limited_llm_call(
                    llm.invoke, context_prompt)
                enhanced_query = enhanced_query_response.content
                print(f"Consulta mejorada: {enhanced_query}")

                # Realizar la b√∫squeda con la consulta mejorada
                retrieved_docs = vectorstore.max_marginal_relevance_search(
                    query=enhanced_query,
                    k=6,
                    fetch_k=10,
                    lambda_mult=0.7
                )
            except Exception as e:
                print(f"Error al mejorar la consulta: {e}")
                retrieved_docs = vectorstore.max_marginal_relevance_search(
                    query=query,
                    k=6,
                    fetch_k=10,
                    lambda_mult=0.7
                )
        else:
            retrieved_docs = vectorstore.max_marginal_relevance_search(
                query=query,
                k=6,
                fetch_k=10,
                lambda_mult=0.7
            )

        return direct_answer_generator(llm, query, retrieved_docs, retrieved_docs, conversation_history)

    return Tool(
        name=tool_name,
        description=tool_description,
        func=enhanced_retriever_with_answer,
    )


def create_contextual_retriever_tool(vectorstore, llm, conversation_history=None,
                         tool_name="contextual_retriever",
                         tool_description="Encuentra informaci√≥n amplia del curr√≠culum nacional chileno para fundamentar planificaciones educativas completas."):
    """
    Crea una herramienta para b√∫squedas basadas en el contexto de la conversaci√≥n.
    """
    def contextual_retriever_with_answer(query: str) -> str:
        print(f"Ejecutando b√∫squeda contextual para: {query}")

        # If we have conversation history, use it to enhance the query
        if conversation_history and len(conversation_history) > 0:
            # Extract last 2 exchanges (up to 4 messages)
            recent_history = conversation_history[-4:] if len(
                conversation_history) >= 4 else conversation_history

            # Format as text for context
            history_text = "\n".join([msg.content for msg in recent_history])

            # Create a context-aware search prompt
            context_prompt = SystemMessage(content="""
            Como experto en curr√≠culum chileno, tu objetivo es reformular la consulta para obtener informaci√≥n contextual completa que ayude al docente a:

            1. Comprender marcos curriculares completos por nivel educativo (desde sala cuna hasta educaci√≥n media)
            2. Identificar conexiones entre asignaturas y objetivos de aprendizaje transversales
            3. Fundamentar planificaciones anuales o mensuales con criterios oficiales

            Reformula la consulta para extraer informaci√≥n curricular amplia y contextualizada.
            """)

            try:
                enhanced_query_response = rate_limited_llm_call(
                    llm.invoke, context_prompt.format_messages())
                enhanced_query = enhanced_query_response.content.strip()
                print(f"Consulta mejorada: {enhanced_query}")

                # Use the enhanced query
                retrieved_docs = vectorstore.similarity_search(
                    query=enhanced_query,
                    k=5  # Get more docs for contextual understanding
                )
            except Exception as e:
                print(f"Error al mejorar la consulta: {e}")
                # Fallback to original query
                retrieved_docs = vectorstore.similarity_search(
                    query=query,
                    k=4
                )
        else:
            # No history available, use standard search
            retrieved_docs = vectorstore.similarity_search(
                query=query,
                k=4
            )

        # Generate response
        return direct_answer_generator(llm, query, retrieved_docs, retrieved_docs, conversation_history)

    return Tool(
        name=tool_name,
        description=tool_description,
        func=contextual_retriever_with_answer,
    )


def create_strategic_search_tool(vectorstore, llm, conversation_history=None,
                               tool_name="strategic_curriculum_search",
                               tool_description="Realiza una b√∫squeda estrat√©gica en todos los recursos curriculares siguiendo un orden espec√≠fico para planificaciones completas."):

    context_prompt = SystemMessage(content="""
    Como especialista en curr√≠culum chileno, sigue este proceso de b√∫squeda estrat√©gica:

    1. LEYES: Identifica los requisitos normativos aplicables
    2. ORIENTACIONES: Comprende la estructura recomendada
    3. BASES CURRICULARES: Encuentra objetivos espec√≠ficos por nivel y asignatura
    4. PROPUESTAS: Busca planificaciones existentes similares
    5. ACTIVIDADES SUGERIDAS: Complementa con actividades concretas

    Reformula la consulta del usuario para encontrar informaci√≥n siguiendo este orden preciso.
    """)

    def strategic_search_with_answer(query: str) -> str:
        # Extraer nivel y asignatura de la consulta
        extraction_prompt = [
            context_prompt,
            HumanMessage(
                content=f"Extrae el nivel educativo y asignatura de esta consulta: '{query}'. Responde solo con el formato 'NIVEL: X, ASIGNATURA: Y'.")
        ]
        extraction_response = rate_limited_llm_call(
            llm.invoke, extraction_prompt).content

        try:
            nivel = extraction_response.split(
                "NIVEL:")[1].split(",")[0].strip()
            asignatura = extraction_response.split("ASIGNATURA:")[1].strip()
        except:
            nivel = ""
            asignatura = ""

        results = []

        # Paso 1: Buscar en leyes
        legal_query = f"requisitos normativos para planificaciones educativas en {nivel} {asignatura}"
        legal_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={
                                                   "k": 2, "filter": {"source": {"$contains": "leyes"}}})
        legal_docs = legal_retriever.get_relevant_documents(legal_query)
        if legal_docs:
            results.append("MARCO NORMATIVO:")
            for doc in legal_docs:
                results.append(doc.page_content[:500] + "...")

        # Paso 2: Buscar en orientaciones
        orientation_query = f"orientaciones para planificaci√≥n en {nivel} {asignatura}"
        orientation_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={
                                                         "k": 2, "filter": {"source": {"$contains": "orientaciones"}}})
        orientation_docs = orientation_retriever.get_relevant_documents(
            orientation_query)
        if orientation_docs:
            results.append("\nORIENTACIONES:")
            for doc in orientation_docs:
                results.append(doc.page_content[:500] + "...")

        # Paso 3: Buscar en bases curriculares
        curriculum_query = f"objetivos de aprendizaje {nivel} {asignatura}"
        curriculum_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={
                                                        "k": 3, "filter": {"source": {"$contains": "bases curriculares"}}})
        curriculum_docs = curriculum_retriever.get_relevant_documents(
            curriculum_query)
        if curriculum_docs:
            results.append("\nBASES CURRICULARES:")
            for doc in curriculum_docs:
                results.append(doc.page_content[:500] + "...")

        # Paso 4: Buscar en propuestas
        proposal_query = f"propuesta planificaci√≥n {nivel} {asignatura} {query}"
        proposal_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={
                                                      "k": 2, "filter": {"source": {"$contains": "propuesta"}}})
        proposal_docs = proposal_retriever.get_relevant_documents(
            proposal_query)
        if proposal_docs:
            results.append("\nPROPUESTAS EXISTENTES:")
            for doc in proposal_docs:
                results.append(doc.page_content[:500] + "...")

        # Paso 5: Buscar en actividades sugeridas
        activity_query = f"actividades sugeridas {nivel} {asignatura} {query}"
        activity_retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={
                                                      "k": 3, "filter": {"source": {"$contains": "actividades sugeridas"}}})
        activity_docs = activity_retriever.get_relevant_documents(
            activity_query)
        if activity_docs:
            results.append("\nACTIVIDADES SUGERIDAS:")
            for doc in activity_docs:
                results.append(doc.page_content[:500] + "...")

        if not results:
            return "No se encontr√≥ informaci√≥n espec√≠fica siguiendo el proceso de b√∫squeda estrat√©gica."

        return "\n".join(results)

    return Tool(
        name=tool_name,
        func=strategic_search_with_answer,
        description=tool_description
    )


def create_agent(llm, tools):
    """
    Creates a LangChain agent with an improved prompt that emphasizes
    contextual understanding and helpfulness over precision.
    """
    # Obtener nombres de herramientas
    tool_names = ", ".join([tool.name for tool in tools])

    # Define the prompt with emphasis on being helpful with available information
    system_message = f"""Eres un asistente especializado para docentes chilenos que ayuda en la creaci√≥n de tres tipos espec√≠ficos de contenido educativo:

    1. PLANIFICACIONES:
       - Anuales, semestrales o mensuales
       - Incluyen: objetivo general, objetivos espec√≠ficos (m√≠nimo 5), contenidos y habilidades asociadas (m√≠nimo 5)
       - Adaptadas al nivel educativo solicitado

    2. EVALUACIONES:
       - 10 preguntas total:
         * 8 preguntas de selecci√≥n m√∫ltiple
         * 2 preguntas de desarrollo
       - Incluye respuestas gu√≠a para todas las preguntas
       - Adaptadas al nivel y asignatura

    3. GU√çAS DE ESTUDIO:
       - Contenido espec√≠fico por asignatura y tema
       - Formato de repaso estructurado y sencillo
       - Incluye ejemplos y ejercicios pr√°cticos

    PROCESO DE RESPUESTA:
    1. INTERPRETAR la solicitud del usuario para identificar qu√© tipo de contenido necesita
    2. GENERAR SOLO el tipo de contenido solicitado (no generar los otros tipos)
    3. Si no hay informaci√≥n espec√≠fica en el contexto, OFRECER una alternativa aclarando que no est√° basada en los documentos disponibles


    Aspectos a considerar, estos son los niveles educativos que tiene el sistema nacional chileno:
    - Niveles: Sala Cuna (0-2 a√±os), Nivel Medio (2-4 a√±os), Transici√≥n (4-6 a√±os)
    - Educaci√≥n B√°sica (1¬∞ a 6¬∞ B√°sico)
    - Educaci√≥n Media (7¬∞ b√°sico a 2¬∞ medio)
    - Educaci√≥n Media diferenciada (3¬∞ a 4¬∞ medio. Cient√≠fico-Humanista, T√©cnico Profesional, Art√≠stica)
    Tienes acceso a las siguientes herramientas:
    {tool_names}

    ORGANIZACI√ìN DE CONTENIDOS:
    - LEYES: Marco normativo que define los l√≠mites y requisitos de planificaciones educativas
    - ORIENTACIONES: Gu√≠as generales sobre c√≥mo estructurar planificaciones y evaluaciones
    - BASES CURRICULARES: Documentos oficiales con objetivos de aprendizaje por nivel y asignatura
    - PROPUESTAS: Ejemplos de planificaciones que puedes adaptar (prioriza usar estas antes de crear desde cero)
    - ACTIVIDADES SUGERIDAS: Actividades espec√≠ficas que complementan las planificaciones

    INSTRUCCIONES IMPORTANTES:
    1. SIEMPRE identifica primero qu√© tipo de contenido necesita el usuario
    2. GENERA √öNICAMENTE el tipo de contenido solicitado
    3. MANT√âN el formato espec√≠fico para cada tipo de contenido
    4. Si no encuentras informaci√≥n espec√≠fica, OFRECE alternativas aclarando que no est√°n basadas en el contexto
    5. S√© conversacional y natural en tus respuestas

    Para usar una herramienta, utiliza el siguiente formato:
    Thought: Primero, necesito pensar qu√© hacer
    Action: la acci√≥n a realizar, debe ser una de [{tool_names}]
    Action Input: la entrada para la acci√≥n
    Observation: el resultado de la acci√≥n
    ... (este proceso puede repetirse si es necesario)
    Thought: Ahora conozco la respuesta final
    Final Answer: la respuesta final a la pregunta original

    Utiliza siempre el formato anterior, comenzando con un Thought e incluyendo los pasos Action/Action Input necesarios antes de proporcionar una Final Answer.

    Question: {input}
    """

    prompt = PromptTemplate(
        template=system_message + "\n\nQuestion: {input}",
        input_variables=["input", "agent_scratchpad"]
    )

    # Create the agent
    agent = create_react_agent(llm, tools, prompt)

    # Create the agent executor with improved settings
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=2,  # Limit to prevent loops
        early_stopping_method="force",  # Force stop after max iterations
        return_intermediate_steps=True  # Return the steps for tracing
    )

    return agent_executor

# Define the state schema as a TypedDict


class AgentState(TypedDict):
    messages: List[Any]  # Store conversation messages
    next_steps: List[Dict[str, str]]  # Store next actions to take
    tool_results: Dict[str, str]  # Store results from tools
    current_tool: Optional[str]  # Track which tool is being used
    conversation_summary: Optional[str]  # Store conversation summary
    thread_id: Optional[str]  # Agregamos thread_id al estado


def create_langgraph_agent(llm, tools):
    """
    Creates a LangGraph-based agent with robust memory management.
    """
    workflow = StateGraph(MessagesState)

    # Define trimmer para mantener un contexto manejable
    trimmer = trim_messages(strategy="last", max_tokens=16, token_counter=len)

    def call_model(state: MessagesState) -> dict:
        """Process the messages with conversation history."""
        messages = state["messages"]

        # Sistema base y contexto
        system_prompt = SystemMessage(content="""
        Eres un asistente experto en an√°lisis de documentos curriculares chilenos.
        Tienes acceso al historial de la conversaci√≥n y debes usarlo para proporcionar respuestas contextualizadas.
        """)

        # Usar el trimmer para mantener solo los mensajes relevantes
        context_messages = [system_prompt, *trimmer.invoke(messages)]

        try:
            # Encontrar la herramienta apropiada
            tool = next((t for t in tools if t.name ==
                        "enhanced_pdf_retriever"), None)
            if not tool:
                return {
                    "messages": add_messages(
                        messages,
                        AIMessage(
                            content="Error: No se encontr√≥ la herramienta de b√∫squeda.")
                    )
                }

            # Extraer la √∫ltima pregunta
            user_question = None
            for msg in reversed(messages):
                if isinstance(msg, HumanMessage):
                    user_question = msg.content
                    break

            if not user_question:
                return {
                    "messages": add_messages(
                        messages,
                        AIMessage(
                            content="No entend√≠ tu pregunta. ¬øPuedes reformularla?")
                    )
                }

            # Usar la herramienta con el contexto
            result = tool.func(user_question)

            # Generar respuesta
            final_prompt = [
                *context_messages,
                HumanMessage(content=f"""
                Bas√°ndote en la informaci√≥n encontrada:
                {result}

                Proporciona una respuesta clara y √∫til.
                """)
            ]

            final_response = rate_limited_llm_call(llm.invoke, final_prompt)

            return {
                "messages": add_messages(
                    messages,
                    AIMessage(content=final_response.content)
                )
            }

        except Exception as e:
            print(f"Error en call_model: {e}")
            return {
                "messages": add_messages(
                    messages,
                    AIMessage(
                        content=f"Hubo un error al procesar tu pregunta: {str(e)}")
                )
            }

    # Configurar el grafo
    workflow.add_node("call_model", call_model)
    workflow.set_entry_point("call_model")
    workflow.add_edge("call_model", END)

    # Crear el memory saver y compilar
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    return app


def format_and_save_conversation(query: str, response: str, thread_id: str, output_dir: str = "conversaciones") -> str:
    """
    Formatea y guarda la conversaci√≥n en un archivo Markdown usando el thread_id.
    """
    # Crear directorio si no existe
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Usar el thread_id en el nombre del archivo
    filename = f"conversacion_N¬∞_{thread_id}.md"
    filepath = os.path.join(output_dir, filename)

    # Si el archivo ya existe, a√±adir al contenido existente
    existing_content = ""
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            existing_content = f.read()

    # Formatear el nuevo contenido
    new_content = f"""
## Pregunta
{query}

## Respuesta
{response}

---
"""

    # Combinar contenido existente con nuevo contenido
    markdown_content = existing_content + new_content if existing_content else f"""# Conversaci√≥n RAG - Thread ID: {thread_id}
Iniciada el: {time.strftime("%d/%m/%Y %H:%M:%S")}

{new_content}"""

    # Guardar el archivo
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(markdown_content)

    print(f"\nüíæ Conversaci√≥n guardada en: {filepath}")
    return filepath

# ==================== AGENTES ESPECIALIZADOS ====================


def create_planning_agent(llm, vectorstore):
    """
    Crea un agente especializado en planificaciones educativas.
    Verifica que tenga asignatura y nivel antes de generar contenido.
    """
    system_prompt = """Eres un agente especializado en CREAR PLANIFICACIONES EDUCATIVAS para el sistema chileno.

    DEBES verificar que tengas estos dos datos esenciales:
    1. ASIGNATURA (Lenguaje, Matem√°ticas, Historia, Ciencias, etc.)
    2. NIVEL (Espec√≠fico: 1¬∞ b√°sico, 7¬∞ b√°sico, 2¬∞ medio, etc.)

    Si falta alguno de estos datos, SOLICITA espec√≠ficamente la informaci√≥n faltante.

    Una vez que tengas ambos datos, genera una planificaci√≥n completa con:
    - Objetivo general (extra√≠do de las bases curriculares)
    - Objetivos espec√≠ficos (m√≠nimo 5, basados en el curr√≠culum)
    - Contenidos/habilidades (m√≠nimo 5, alineados con bases curriculares)
    - Actividades (m√≠nimo 3, detalladas y acordes al nivel)
    - Evaluaci√≥n sugerida (m√©todos para verificar aprendizaje)

    Formatea tu respuesta de manera clara y estructurada. Cita las fuentes curriculares espec√≠ficas.
    """

    def planning_agent_executor(query, asignatura=None, nivel=None):
        # Verificar informaci√≥n faltante
        faltante = []
        if not asignatura:
            # Intentar extraer asignatura de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae la asignatura mencionada en esta solicitud. Si no hay ninguna, responde 'No especificada'."),
                HumanMessage(content=query)
            ]
            asignatura_result = rate_limited_llm_call(
                llm.invoke, extract_prompt)
            if "No especificada" in asignatura_result.content:
                faltante.append("asignatura")
            else:
                asignatura = asignatura_result.content.strip()

        if not nivel:
            # Intentar extraer nivel de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae el nivel educativo mencionado en esta solicitud (ej: 5¬∞ b√°sico, 2¬∞ medio). Si no hay ninguno, responde 'No especificado'."),
                HumanMessage(content=query)
            ]
            nivel_result = rate_limited_llm_call(llm.invoke, extract_prompt)
            if "No especificado" in nivel_result.content:
                faltante.append("nivel")
            else:
                nivel = nivel_result.content.strip()

        # Si falta informaci√≥n, solicitarla
        if faltante:
            response = "Para crear una planificaci√≥n educativa completa, necesito la siguiente informaci√≥n:\n\n"
            if "asignatura" in faltante:
                response += "- ¬øPara qu√© asignatura necesitas la planificaci√≥n? (Lenguaje, Matem√°ticas, etc.)\n"
            if "nivel" in faltante:
                response += "- ¬øPara qu√© nivel educativo? (Ej: 2¬∞ b√°sico, 8¬∞ b√°sico, 3¬∞ medio, etc.)\n"
            return response, True, {"asignatura": asignatura, "nivel": nivel}

        # Si tenemos toda la informaci√≥n, generar la planificaci√≥n
        enhanced_query = f"Crear planificaci√≥n para la asignatura de {asignatura} para el nivel {nivel}"

        # Buscar informaci√≥n relevante en el vectorstore
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5, "fetch_k": 10}
        )

        retrieved_docs = retriever.get_relevant_documents(enhanced_query)
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])

        # Generar la planificaci√≥n
        prompt = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"""
            Solicitud: {query}
            Asignatura: {asignatura}
            Nivel: {nivel}

            Informaci√≥n curricular relevante:
            {context}
            """)
        ]

        response = rate_limited_llm_call(llm.invoke, prompt)
        return response.content, False, {"asignatura": asignatura, "nivel": nivel}

    return planning_agent_executor


def create_evaluation_agent(llm, vectorstore):
    """
    Crea un agente especializado en evaluaciones educativas.
    Verifica que tenga asignatura y nivel antes de generar contenido.
    """
    system_prompt = """Eres un agente especializado en CREAR EVALUACIONES EDUCATIVAS para el sistema chileno.

    DEBES verificar que tengas estos dos datos esenciales:
    1. ASIGNATURA (Lenguaje, Matem√°ticas, Historia, Ciencias, etc.)
    2. NIVEL (Espec√≠fico: 1¬∞ b√°sico, 7¬∞ b√°sico, 2¬∞ medio, etc.)

    Si falta alguno de estos datos, SOLICITA espec√≠ficamente la informaci√≥n faltante.

    Una vez que tengas ambos datos, genera una evaluaci√≥n completa con:
    - 8 preguntas de selecci√≥n m√∫ltiple con 4 opciones cada una
    - 2 preguntas de desarrollo que eval√∫en habilidades superiores
    - Respuestas correctas y r√∫bricas de evaluaci√≥n para las preguntas de desarrollo

    Las preguntas deben estar alineadas con los objetivos de aprendizaje del curr√≠culum nacional
    para la asignatura y nivel especificados.

    Formatea tu respuesta con n√∫meros claros para cada pregunta y letras para las alternativas.
    """

    def evaluation_agent_executor(query, asignatura=None, nivel=None):
        # Verificar informaci√≥n faltante
        faltante = []
        if not asignatura:
            # Intentar extraer asignatura de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae la asignatura mencionada en esta solicitud. Si no hay ninguna, responde 'No especificada'."),
                HumanMessage(content=query)
            ]
            asignatura_result = rate_limited_llm_call(
                llm.invoke, extract_prompt)
            if "No especificada" in asignatura_result.content:
                faltante.append("asignatura")
            else:
                asignatura = asignatura_result.content.strip()

        if not nivel:
            # Intentar extraer nivel de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae el nivel educativo mencionado en esta solicitud (ej: 5¬∞ b√°sico, 2¬∞ medio). Si no hay ninguno, responde 'No especificado'."),
                HumanMessage(content=query)
            ]
            nivel_result = rate_limited_llm_call(llm.invoke, extract_prompt)
            if "No especificado" in nivel_result.content:
                faltante.append("nivel")
            else:
                nivel = nivel_result.content.strip()

        # Si falta informaci√≥n, solicitarla
        if faltante:
            response = "Para crear una evaluaci√≥n completa, necesito la siguiente informaci√≥n:\n\n"
            if "asignatura" in faltante:
                response += "- ¬øPara qu√© asignatura necesitas la evaluaci√≥n? (Lenguaje, Matem√°ticas, etc.)\n"
            if "nivel" in faltante:
                response += "- ¬øPara qu√© nivel educativo? (Ej: 2¬∞ b√°sico, 8¬∞ b√°sico, 3¬∞ medio, etc.)\n"
            return response, True, {"asignatura": asignatura, "nivel": nivel}

        # Si tenemos toda la informaci√≥n, generar la evaluaci√≥n
        enhanced_query = f"Crear evaluaci√≥n para la asignatura de {asignatura} para el nivel {nivel}"

        # Buscar informaci√≥n relevante en el vectorstore
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5, "fetch_k": 10}
        )

        retrieved_docs = retriever.get_relevant_documents(enhanced_query)
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])

        # Generar la evaluaci√≥n
        prompt = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"""
            Solicitud: {query}
            Asignatura: {asignatura}
            Nivel: {nivel}

            Objetivos de aprendizaje y contenidos relevantes:
            {context}
            """)
        ]

        response = rate_limited_llm_call(llm.invoke, prompt)
        return response.content, False, {"asignatura": asignatura, "nivel": nivel}

    return evaluation_agent_executor


def create_study_guide_agent(llm, vectorstore):
    """
    Crea un agente especializado en gu√≠as de estudio.
    Verifica que tenga asignatura y nivel antes de generar contenido.
    """
    system_prompt = """Eres un agente especializado en CREAR GU√çAS DE ESTUDIO para el sistema educativo chileno.

    DEBES verificar que tengas estos dos datos esenciales:
    1. ASIGNATURA (Lenguaje, Matem√°ticas, Historia, Ciencias, etc.)
    2. NIVEL (Espec√≠fico: 1¬∞ b√°sico, 7¬∞ b√°sico, 2¬∞ medio, etc.)

    Si falta alguno de estos datos, SOLICITA espec√≠ficamente la informaci√≥n faltante.

    Una vez que tengas ambos datos, genera una gu√≠a de estudio completa con:
    - Resumen del tema principal
    - Conceptos clave (definiciones claras)
    - Ejemplos resueltos paso a paso
    - Ejercicios de pr√°ctica graduados por dificultad
    - Respuestas o soluciones a los ejercicios propuestos

    La gu√≠a debe estar alineada con el curr√≠culum nacional y usar lenguaje apropiado para el nivel.

    Organiza la gu√≠a con t√≠tulos claros y formato amigable para estudiantes.
    """

    def study_guide_agent_executor(query, asignatura=None, nivel=None):
        # Verificar informaci√≥n faltante
        faltante = []
        if not asignatura:
            # Intentar extraer asignatura de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae la asignatura mencionada en esta solicitud. Si no hay ninguna, responde 'No especificada'."),
                HumanMessage(content=query)
            ]
            asignatura_result = rate_limited_llm_call(
                llm.invoke, extract_prompt)
            if "No especificada" in asignatura_result.content:
                faltante.append("asignatura")
            else:
                asignatura = asignatura_result.content.strip()

        if not nivel:
            # Intentar extraer nivel de la consulta
            extract_prompt = [
                SystemMessage(
                    content="Extrae el nivel educativo mencionado en esta solicitud (ej: 5¬∞ b√°sico, 2¬∞ medio). Si no hay ninguno, responde 'No especificado'."),
                HumanMessage(content=query)
            ]
            nivel_result = rate_limited_llm_call(llm.invoke, extract_prompt)
            if "No especificado" in nivel_result.content:
                faltante.append("nivel")
            else:
                nivel = nivel_result.content.strip()

        # Si falta informaci√≥n, solicitarla
        if faltante:
            response = "Para crear una gu√≠a de estudio completa, necesito la siguiente informaci√≥n:\n\n"
            if "asignatura" in faltante:
                response += "- ¬øPara qu√© asignatura necesitas la gu√≠a? (Lenguaje, Matem√°ticas, etc.)\n"
            if "nivel" in faltante:
                response += "- ¬øPara qu√© nivel educativo? (Ej: 2¬∞ b√°sico, 8¬∞ b√°sico, 3¬∞ medio, etc.)\n"
            return response, True, {"asignatura": asignatura, "nivel": nivel}

        # Si tenemos toda la informaci√≥n, generar la gu√≠a
        enhanced_query = f"Crear gu√≠a de estudio para la asignatura de {asignatura} para el nivel {nivel}"

        # Buscar informaci√≥n relevante en el vectorstore
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5, "fetch_k": 10}
        )

        retrieved_docs = retriever.get_relevant_documents(enhanced_query)
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])

        # Generar la gu√≠a
        prompt = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"""
            Solicitud: {query}
            Asignatura: {asignatura}
            Nivel: {nivel}

            Contenidos y objetivos de aprendizaje relevantes:
            {context}
            """)
        ]

        response = rate_limited_llm_call(llm.invoke, prompt)
        return response.content, False, {"asignatura": asignatura, "nivel": nivel}

    return study_guide_agent_executor


def create_router_agent(llm, planning_agent, evaluation_agent, study_guide_agent):
    """
    Crea un agente router que identifica el tipo de solicitud, verifica informaci√≥n
    completa y solo cuando tiene todos los datos necesarios deriva al especialista.
    """
    system_prompt = """Eres un agente router inteligente que analiza solicitudes educativas.
    
    Tu funci√≥n es triple:
    
    1. IDENTIFICAR el tipo de contenido educativo solicitado:
       - PLANIFICACION (planes de clase, anuales, unidades, etc.)
       - EVALUACION (pruebas, ex√°menes, r√∫bricas, etc.)
       - GUIA (gu√≠as de estudio, material de repaso, fichas, etc.)
    
    2. VERIFICAR que la solicitud contenga estos dos datos ESENCIALES:
       - ASIGNATURA (Lenguaje, Matem√°ticas, Historia, Ciencias, etc.)
       - NIVEL EDUCATIVO (1¬∞ b√°sico, 5¬∞ b√°sico, 2¬∞ medio, etc.)
    
    3. DETERMINAR si falta informaci√≥n para procesar la solicitud
    
    Responde SOLO en formato JSON con esta estructura:
    {
        "tipo": "PLANIFICACION|EVALUACION|GUIA",
        "asignatura": "nombre de la asignatura o null",
        "nivel": "nivel educativo o null",
        "informacion_completa": true/false,
        "informacion_faltante": ["asignatura", "nivel"] o [] si no falta nada
    }
    
    IMPORTANTE: Usa comillas dobles para las cadenas y null para valores nulos.
    """
    
    def router_execute(query, asignatura=None, nivel=None):
        """
        Funci√≥n del router que analiza la consulta, solicita informaci√≥n faltante
        y deriva al especialista adecuado cuando tiene todos los datos.
        
        Args:
            query: Consulta del usuario
            asignatura: Asignatura previamente identificada (opcional)
            nivel: Nivel educativo previamente identificado (opcional)
            
        Returns:
            Tupla con (respuesta, necesita_info, info_actual, tipo_contenido)
        """
        # Si ya tenemos asignatura y nivel, no necesitamos analizar de nuevo
        if asignatura and nivel:
            # Determinar tipo de contenido
            prompt = [
                SystemMessage(content="Identifica qu√© tipo de contenido educativo solicita el usuario: PLANIFICACION, EVALUACION o GUIA. Responde solo con una de estas palabras."),
                HumanMessage(content=query)
            ]
            result = rate_limited_llm_call(llm.invoke, prompt)
            tipo = result.content.strip().upper()
            
            # Normalizar el tipo
            if "PLAN" in tipo:
                tipo = "PLANIFICACION"
            elif "EVAL" in tipo:
                tipo = "EVALUACION"
            elif "GU" in tipo:
                tipo = "GUIA"
            else:
                tipo = "PLANIFICACION"  # Por defecto
            
            # Derivar directamente al especialista
            if tipo == "PLANIFICACION":
                response, _, _ = planning_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "PLANIFICACION"
            elif tipo == "EVALUACION":
                response, _, _ = evaluation_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "EVALUACION"
            else:  # GUIA
                response, _, _ = study_guide_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "GUIA"
        
        # Si no tenemos toda la informaci√≥n, analizamos la consulta
        prompt = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=query)
        ]
        
        result = rate_limited_llm_call(llm.invoke, prompt)
        
        try:
            # Parsear el resultado JSON de forma segura
            import json
            import re
            
            # Extraer el bloque JSON de la respuesta
            json_str = result.content
            # Encontrar el primer '{' y el √∫ltimo '}'
            start = json_str.find('{')
            end = json_str.rfind('}') + 1
            if start != -1 and end != 0:
                json_str = json_str[start:end]
            
            # Limpiar y normalizar el JSON
            json_str = json_str.replace("'", '"')
            # Reemplazar valores de texto null por null de JSON
            json_str = re.sub(r'"null"', 'null', json_str)
            
            # Parsear el JSON limpio
            decision = json.loads(json_str)
            
            tipo = decision.get("tipo", "").upper()
            # Usar los valores pasados por par√°metro si est√°n disponibles
            asignatura = asignatura or decision.get("asignatura")
            nivel = nivel or decision.get("nivel")
            
            # Convertir "null" a None
            if asignatura == "null" or asignatura == "NULL":
                asignatura = None
            if nivel == "null" or nivel == "NULL":
                nivel = None
            
            # Verificar si necesitamos m√°s informaci√≥n
            informacion_completa = decision.get("informacion_completa", False)
            informacion_faltante = decision.get("informacion_faltante", [])
            
            # Si falta informaci√≥n, solicitarla
            if not informacion_completa or not asignatura or not nivel:
                response = "Para ayudarte mejor, necesito la siguiente informaci√≥n:\n\n"
                
                if not asignatura:
                    response += "- ¬øPara qu√© asignatura necesitas el material? (Ej: Matem√°ticas, Lenguaje, etc.)\n"
                if not nivel:
                    response += "- ¬øPara qu√© nivel educativo? (Ej: 2¬∞ b√°sico, 8¬∞ b√°sico, 3¬∞ medio, etc.)\n"
                
                return response, True, {"asignatura": asignatura, "nivel": nivel}, tipo
            
            # Si tenemos toda la informaci√≥n, derivar al especialista
            if tipo == "PLANIFICACION":
                response, _, _ = planning_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "PLANIFICACION"
            elif tipo == "EVALUACION":
                response, _, _ = evaluation_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "EVALUACION"
            elif tipo == "GUIA":
                response, _, _ = study_guide_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "GUIA"
            else:
                # Por defecto, usar planificaci√≥n
                response, _, _ = planning_agent(query, asignatura, nivel)
                return response, False, {"asignatura": asignatura, "nivel": nivel}, "PLANIFICACION"
                
        except Exception as e:
            print(f"\n‚ö†Ô∏è Error al procesar la decisi√≥n: {e}")
            print(f"Respuesta original del LLM: {result.content}")
            
            # Intentar extraer tipo, asignatura y nivel de forma b√°sica
            tipo_match = re.search(r'(PLANIFICACI[O√ì]N|EVALUACI[O√ì]N|GU[I√ç]A)', query.upper())
            tipo = "PLANIFICACION"  # Valor predeterminado
            if tipo_match:
                if "PLAN" in tipo_match.group(0):
                    tipo = "PLANIFICACION"
                elif "EVAL" in tipo_match.group(0):
                    tipo = "EVALUACION"
                elif "GUI" in tipo_match.group(0):
                    tipo = "GUIA"
            
            # Verificar si tenemos informaci√≥n suficiente para continuar
            if asignatura and nivel:
                # Si tenemos asignatura y nivel, podemos continuar con el especialista
                if tipo == "PLANIFICACION":
                    response, _, _ = planning_agent(query, asignatura, nivel)
                    return response, False, {"asignatura": asignatura, "nivel": nivel}, "PLANIFICACION"
                elif tipo == "EVALUACION":
                    response, _, _ = evaluation_agent(query, asignatura, nivel)
                    return response, False, {"asignatura": asignatura, "nivel": nivel}, "EVALUACION"
                else:  # GUIA
                    response, _, _ = study_guide_agent(query, asignatura, nivel)
                    return response, False, {"asignatura": asignatura, "nivel": nivel}, "GUIA"
            else:
                # Si falta informaci√≥n, solicitarla
                response = "Para ayudarte mejor, necesito la siguiente informaci√≥n:\n\n"
                if not asignatura:
                    response += "- ¬øPara qu√© asignatura necesitas el material? (Ej: Matem√°ticas, Lenguaje, etc.)\n"
                if not nivel:
                    response += "- ¬øPara qu√© nivel educativo? (Ej: 2¬∞ b√°sico, 8¬∞ b√°sico, 3¬∞ medio, etc.)\n"
                
                return response, True, {"asignatura": asignatura, "nivel": nivel}, tipo
    
    return router_execute

# Modificaci√≥n de la funci√≥n main para implementar arquitectura multi-agente


def main():
    print("Inicializando Sistema Multi-Agente Educativo...")

    # Configurar el LLM
    llm = ChatVertexAI(
        model_name="gemini-1.5-flash",
        temperature=0.5,
        max_output_tokens=8192,
        top_p=0.95,
        top_k=40
    )

    embeddings = VertexAIEmbeddings(model_name="text-multilingual-embedding-002")

    # Verificar si ya existe la base de datos de Chroma
    collection_name = "pdf-rag-chroma"
    persist_directory = f"./{collection_name}"

    try:
        if os.path.exists(persist_directory):
            print("\nüìö Cargando base de datos existente...")
            vectorstore = Chroma(
                persist_directory=persist_directory,
                embedding_function=embeddings,
                collection_name=collection_name
            )
            collection_size = len(vectorstore.get()['ids'])
            if collection_size > 0:
                print(
                    f"‚úÖ Base de datos cargada exitosamente con {collection_size} documentos")
            else:
                raise ValueError("La base de datos existe pero est√° vac√≠a")
        else:
            # Solo cargar PDFs si necesitamos crear una nueva base de datos
            print(
                "\nüìÑ No se encontr√≥ base de datos existente. Cargando documentos PDF...")
            pdf_directory = "pdf_docs"
            if not os.path.exists(pdf_directory):
                os.makedirs(pdf_directory)
                print(f"üìÅ Se cre√≥ el directorio: {pdf_directory}")
                print("‚ùå Por favor, coloca archivos PDF en el directorio y reinicia el programa.")
                return

            documents = load_pdf_documents(pdf_directory)
            if not documents:
                print("‚ùå No se encontraron documentos PDF. Por favor, agrega archivos PDF y reinicia.")
                return

            print(f"‚úÖ Se cargaron {len(documents)} p√°ginas de documentos PDF")
            
            # Crear nueva base de datos
            print("\nüîÑ Creando nueva base de datos...")
            vectorstore = create_vectorstore(documents, embeddings, collection_name)
            
    except Exception as e:
        print(f"\n‚ùå Error al inicializar la base de datos: {e}")
        return

    # Crear agentes especializados
    print("\nü§ñ Creando agentes especializados...")
    planning_agent = create_planning_agent(llm, vectorstore)
    evaluation_agent = create_evaluation_agent(llm, vectorstore)
    study_guide_agent = create_study_guide_agent(llm, vectorstore)
    
    # Crear agente router
    print("üß≠ Creando agente router...")
    router = create_router_agent(llm, planning_agent, evaluation_agent, study_guide_agent)

    print("\n" + "="*50)
    print("üéØ Sistema Multi-Agente Educativo listo!")
    print("Haz preguntas sobre planificaciones, evaluaciones o gu√≠as de estudio")
    print("="*50)

    # Generar un ID de sesi√≥n √∫nico
    thread_id = str(uuid.uuid4())[:8]
    print(f"\nüîë ID de sesi√≥n: {thread_id}")
    
    # Estado para mantener informaci√≥n entre turnos de conversaci√≥n
    session_state = {
        "pending_request": False,
        "last_query": "",
        "asignatura": None,
        "nivel": None,
        "tipo": None
    }

    while True:
        query = input("\nüë§ Usuario: ")
        if query.lower() in ["exit", "quit", "q"]:
            print("\nüëã Saliendo del sistema. ¬°Hasta luego!")
            break

        try:
            # Si hay una solicitud pendiente de informaci√≥n
            if session_state["pending_request"]:
                # La nueva consulta podr√≠a contener la asignatura o el nivel
                if not session_state["asignatura"]:
                    session_state["asignatura"] = query
                    print("\nüîÑ Informaci√≥n registrada. Procesando...")
                    # Volvemos a llamar al router con la nueva informaci√≥n
                    response, needs_info, info, tipo = router(
                        session_state["last_query"], 
                        session_state["asignatura"], 
                        session_state["nivel"]
                    )
                elif not session_state["nivel"]:
                    session_state["nivel"] = query
                    print("\nüîÑ Informaci√≥n registrada. Procesando...")
                    # Volvemos a llamar al router con la nueva informaci√≥n
                    response, needs_info, info, tipo = router(
                        session_state["last_query"], 
                        session_state["asignatura"], 
                        session_state["nivel"]
                    )
                
                if needs_info:
                    # A√∫n falta informaci√≥n
                    print(f"\n‚ùì {response}")
                    session_state["pending_request"] = True
                    # No actualizamos last_query aqu√≠, mantenemos la consulta original
                else:
                    # Tenemos toda la informaci√≥n, mostrar respuesta final
                    print(f"\nü§ñ Respuesta: {response}")
                    # Guardar la conversaci√≥n completa
                    full_query = f"{session_state['last_query']} (Asignatura: {session_state['asignatura']}, Nivel: {session_state['nivel']})"
                    format_and_save_conversation(full_query, response, thread_id)
                    # Reiniciar el estado
                    session_state = {
                        "pending_request": False,
                        "last_query": "",
                        "asignatura": None,
                        "nivel": None,
                        "tipo": None
                    }
            else:
                # Nueva solicitud
                print("\nüîÑ Procesando tu solicitud...")
                response, needs_info, info, tipo = router(query)
                
                if needs_info:
                    # Necesitamos m√°s informaci√≥n
                    print(f"\n‚ùì {response}")
                    session_state = {
                        "pending_request": True,
                        "last_query": query,
                        "asignatura": info.get("asignatura"),
                        "nivel": info.get("nivel"),
                        "tipo": tipo
                    }
                else:
                    # Tenemos toda la informaci√≥n, mostrar respuesta final
                    print(f"\nü§ñ Respuesta: {response}")
                    format_and_save_conversation(query, response, thread_id)
        
        except Exception as e:
            print(f"\n‚ùå Ocurri√≥ un error: {e}")
            print("Por favor, intenta reformular tu solicitud.")
            # Reiniciar el estado en caso de error
            session_state = {
                "pending_request": False,
                "last_query": "",
                "asignatura": None,
                "nivel": None,
                "tipo": None
            }
        
if __name__ == "__main__":
    main()